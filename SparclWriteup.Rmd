---
title: "Sparse Clustering Algorithm"
author: "Paul Harmon"
date: "9/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr);library(ggplot2);library(magrittr)
```

## Introduction

## Sparcl packages

Witten includes several of the important functions called by the sparse clustering package in her Github page (link: https://github.com/cran/sparcl). 

## Datasets: 

I'm using a couple of standard datasets that I like to utilize: 

+ NBA pointguards 
+ Colorado housing prices
+ NFL QB stats

```{r}
#reads in datasets
house <- read_csv("data/house_train.csv")
nba <- read_csv("data/na.csv")
qb <- read_csv("data/QBStats_all.csv")
```

Dimensions of the data are shown below: 
```{r}
dim(house)
dim(nba)
dim(qb)
```


## Sparcl Algorithm

The sparse clustering algorithm can be defined for hierarchical clustering as follows: 

+ Initial clustering solution
+ Update the weights w2 (set usually as $\frac{1}{\sqrt{p}}$)
+ Update u, w until convergence
+ Generate the new dissimilarity matrix U (that is now sparse) and perform hierarchical clustering on it

Based on the above methodology, the actual calculation of the sparse clustering is separate from the hierarchical clustering that is performed in the final step. A different clustering method, such as monothetic clustering, could be easily used in the same framework. 

I could easily read in the 'sparcl' package and apply the function; however, instead I'm using Witten's code piece by piece to get a better sense for how the algorithm works and what is necessary to make changes. 

```{r, include = FALSE, eval = FALSE}
#this code reads in Witten's R-code for Sparcl
`HierarchicalSparseCluster` <-
function(x=NULL, dists=NULL, method=c("average", "complete", "single","centroid"), wbound=NULL,niter=15,dissimilarity=c("squared.distance", "absolute.value"), uorth=NULL, silent=FALSE, cluster.features=FALSE, method.features=c("average", "complete", "single","centroid"),output.cluster.files=FALSE, outputfile.prefix="output",genenames=NULL, genedesc=NULL,standardize.arrays=FALSE){
  method <- match.arg(method)
  method.features <- match.arg(method.features)
  dissimilarity <- match.arg(dissimilarity)
  if (is.null(x) && is.null(dists)) stop("x or dists must be given!!!")
  xorig <- x
  if(standardize.arrays){
    if(is.null(x)) stop("Cannot standardize arrays if x not given.")
    dists <- NULL
    x <- sweep(x,1,apply(x,1,mean,na.rm=TRUE),"-")
    x <- sweep(x,1,apply(x,1,sd,na.rm=TRUE),"/")
  }
  if(is.null(dists)){
    xnona <- x
    xnona[is.na(x)] <- 0
    dists <- matrix(distfun(xnona), ncol=ncol(x)) # Rob's Fortran code!!! - no missing values please
    if(sum(is.na(x))>0){
      xbinary <- matrix(1, nrow=nrow(x),ncol=ncol(x))
      xbinary[is.na(x)] <- 0
      mult <- matrix(multfun(xbinary),ncol=ncol(x)) # mult equals 1 if neither elt is NA, and 0 if one or both is NA
      if(dissimilarity=="squared.distance"){
        dists <- sweep(dists,1,sqrt(ncol(dists)/apply(mult!=0,1,sum)),"*")
      } else if (dissimilarity=="absolute.value"){
        dists <- sweep(dists,1,ncol(dists)/apply(mult!=0,1,sum),"*")
      }
      dists[mult==0] <- 0
      mult <- NULL
      xbinary <- NULL
      xnona <- NULL
    }
  }
  if(is.null(wbound)) wbound <- .5*sqrt(ncol(dists))
  if(wbound<=1) stop("Cannot have wbound <= 1")
  if (dissimilarity == "squared.distance") out <- GetUW(dists^2, wbound, niter = niter, uorth = uorth, silent = silent)
  if (dissimilarity == "absolute.value")  out <- GetUW(dists, wbound, niter = niter, uorth = uorth, silent = silent)
  out <- list(hc = hclust(as.dist(out$u), method = method), ws = out$w, u = out$u, crit = out$crit, dists = dists, uorth = uorth, wbound = wbound)

  if(cluster.features){
    if(is.null(x)) stop("Cannot cluster features unless x is given.")
    rho=cor(xorig[,out$ws!=0],use="pairwise.complete.obs")
    out2 <- hclust(as.dist(2*(1-rho)), method=method.features)
    out$hc.features <- out2
  }

  if(output.cluster.files){
    if(is.null(x)) stop("Cannot output files unless x is given.")
    output.cluster.files.fun(xorig,out,outputfile.prefix,genenames=genenames,genedesc=genedesc)
  }
  if(!silent) cat(fill=TRUE)
  class(out) <- "HierarchicalSparseCluster"
  return(out)
}


plot.HierarchicalSparseCluster <- function(x,...){
  par(mfrow=c(1,2))
  plot(x$hc,xlab="",ylab="",sub="", main="Sparse Clustering", labels=rep("", nrow(x$u)))
  plot(x$ws, main=paste("Wbound is ", sep="", round(x$wbound,3)), xlab="Feature Index", ylab="Wj")
}



print.HierarchicalSparseCluster <- function(x,...){
  cat("Wbound is ", x$wbound, ":", fill=TRUE)
  cat("Number of non-zero weights: ", sum(x$ws!=0), fill=TRUE)
  cat("Sum of weights: ", sum(x$ws), fill=TRUE)
  cat(fill=TRUE)
}
```

Additional functions: 
```{r, echo = FALSE}
GetWCSS <- function(x, Cs, ws=NULL){
  wcss.perfeature <- numeric(ncol(x))
  for(k in unique(Cs)){
    whichers <- (Cs==k)
    if(sum(whichers)>1) wcss.perfeature <- wcss.perfeature + apply(scale(x[whichers,],center=TRUE, scale=FALSE)^2, 2, sum)
  }
  bcss.perfeature <- apply(scale(x, center=TRUE, scale=FALSE)^2, 2, sum)-wcss.perfeature
  if(!is.null(ws)) return(list(wcss.perfeature=wcss.perfeature, wcss=sum(wcss.perfeature), wcss.ws=sum(wcss.perfeature*ws),
                               bcss.perfeature=bcss.perfeature))
  if(is.null(ws)) return(list(wcss.perfeature=wcss.perfeature, wcss=sum(wcss.perfeature), bcss.perfeature=bcss.perfeature))
}
 
UpdateCs <- function(x, K, ws, Cs){
  x <- x[,ws!=0]
  z <- sweep(x, 2, sqrt(ws[ws!=0]), "*")
  nrowz <- nrow(z)
  mus <- NULL
  if(!is.null(Cs)){
    for(k in unique(Cs)){
      if(sum(Cs==k)>1) mus <- rbind(mus, apply(z[Cs==k,],2,mean))
      if(sum(Cs==k)==1) mus <- rbind(mus, z[Cs==k,])
    }
  }
  if(is.null(mus)){
    km <- kmeans(z, centers=K, nstart=10)
  } else {
    distmat <- as.matrix(dist(rbind(z, mus)))[1:nrowz, (nrowz+1):(nrowz+K)]
    nearest <- apply(distmat, 1, which.min)
    if(length(unique(nearest))==K){
      km <- kmeans(z, centers=mus)
    } else {
      km <- kmeans(z, centers=K, nstart=10)
    }
  }
  return(km$cluster)
}

#distmat <- function(x){
#  return(dist(x))
#}

BinarySearch <- function(argu,sumabs){
  if(l2n(argu)==0 || sum(abs(argu/l2n(argu)))<=sumabs) return(0)
  lam1 <- 0
  lam2 <- max(abs(argu))-1e-5
  iter <- 1
  while(iter<=15 && (lam2-lam1)>(1e-4)){
    su <- soft(argu,(lam1+lam2)/2)
    if(sum(abs(su/l2n(su)))<sumabs){
      lam2 <- (lam1+lam2)/2
    } else {
      lam1 <- (lam1+lam2)/2
    }
    iter <- iter+1
  }
  return((lam1+lam2)/2)
}

soft <- function(x,d){
  return(sign(x)*pmax(0, abs(x)-d))
}

l2n <- function(vec){
  return(sqrt(sum(vec^2)))
}

GetUW <- function(ds, wbound,niter,uorth,silent){
  # uorth would be a $n^2 x k$ matrix containing $k$ previous
  # dissimilarity matrices found, if we want to do sparse comp clust
  # after having already done $k$ of these things
  # Example:
  # out <- HierarchicalSparseCluster(x,wbound=5)
  # out2 <- HierarchicalSparseCluster(x,wbound=5, uorth=out$u)
  # Then out2 contains a sparse complementary clustering
  p <- ncol(ds)
  w <- rep(1/p, p)*wbound
  iter <- 1
  if(!is.null(uorth)){
    if(sum(abs(uorth-t(uorth)))>1e-10) stop("Uorth must be symmetric!!!!!!!!!!")
    uorth <- matrix(uorth[lower.tri(uorth)],ncol=1)
    uorth <- uorth/sqrt(sum(uorth^2))
  }
  u <- rnorm(nrow(ds))
  w <- rep(1, ncol(ds))
  w.old <- rnorm(ncol(ds))
#  u.old <- rnorm(nrow(ds))
  while(iter<=niter && (sum(abs(w.old-w))/sum(abs(w.old)))>1e-4){#(sum(abs(u.old-u))/sum(abs(u.old)))>1e-4){ # was 1e-3 and involved ws until 11.12.09
    if(!silent) cat(iter,fill=FALSE)
#    u.old <- u
    if(iter>1) u <- ds[,argw>=lam]%*%matrix(w[argw>=lam],ncol=1) 
    if(iter==1) u <- ds%*%matrix(w,ncol=1)
    if(!is.null(uorth)) u <- u - uorth%*%(t(uorth)%*%u)
    iter <- iter+1
    u <- u/l2n(u)
    w.old <- w
    argw <- matrix(pmax(matrix(u,nrow=1)%*%ds,0),ncol=1) 
    lam <- BinarySearch(argw,wbound)
    w <- soft(argw,lam) # Don't need to normalize b/c this will be done soon
    w <- w/l2n(w)
  } 
  u <-  ds[,argw>=lam]%*%matrix(w[argw>=lam],ncol=1)/sum(w)
  if(!is.null(uorth)) u <- u - uorth%*%(t(uorth)%*%u)
  u <- u/l2n(u)
  w <- w/l2n(w)
  crit <- sum(u*(ds%*%matrix(w,ncol=1)))
  u2 <- matrix(0,nrow=ceiling(sqrt(2*length(u))),ncol=ceiling(sqrt(2*length(u))))
  u2[lower.tri(u2)] <- u
  u <- as.matrix(as.dist(u2))/sqrt(2)
  return(list(u=u, w=w, crit=crit))
}

 
UpdateWs <- function(x, Cs, l1bound){
  wcss.perfeature <- GetWCSS(x, Cs)$wcss.perfeature
  tss.perfeature <- GetWCSS(x, rep(1, nrow(x)))$wcss.perfeature
  lam <- BinarySearch(-wcss.perfeature+tss.perfeature, l1bound)
  ws.unscaled <- soft(-wcss.perfeature+tss.perfeature,lam)
  return(ws.unscaled/l2n(ws.unscaled))
}


output.cluster.files.fun <- function(x,out,outputfile.prefix,genenames=NULL,genedesc=NULL){
         p=ncol(x)
         n=nrow(x)
         geneids=dimnames(x)[[2]]
         samplenames=dimnames(x)[[1]]
         if(is.null(geneids)) geneids <- paste("Gene", 1:ncol(x))
         if(is.null(samplenames)) samplenames <- paste("Sample",1:nrow(x))
         if(is.null(genenames)){genenames=geneids}
         if(is.null(genedesc)){genedesc <- rep("", ncol(x))}

         xx=x[,out$ws!=0]
         geneids.subset=geneids[out$ws!=0]
         genenames.subset=genenames[out$ws!=0]
         genedesc.subset=genedesc[out$ws!=0]
         pp=ncol(xx)
         sample.order=out$hc$order
          samplenames.o=samplenames[sample.order]
         arrynames=paste("ARRY",as.character(sample.order),"X",sep="")
         feature.order=1:pp
   if(!is.null(out$hc.features)){feature.order=out$hc.features$order}
    xx.o=xx[sample.order,feature.order]
    geneids.subset.o=geneids.subset[feature.order]
    genenames.subset.o=genenames.subset[feature.order]
    genedesc.subset.o=genedesc.subset[feature.order]
    genex=paste("GENE",as.character(1:pp),"X",sep="")
    genex.o=genex[feature.order]
    arrynames.o=arrynames[sample.order]

# output cdt
	file=paste(outputfile.prefix,".cdt",sep="")
         xprefix <- rbind(c("GID","UID","NAME","GWEIGHT",samplenames.o),c("AID","","","",arrynames))
         xbig <- matrix(NA, ncol=(n+4),nrow=pp)
         for(i in 1:pp){
           xbig[i,] <- c(genex.o[i],geneids.subset.o[i],genedesc.subset.o[i],"1",xx.o[,i]) # was xx
         }
         xbig <- rbind(xprefix,xbig)
         write.table(file=file,xbig,col.names=FALSE,row.names=FALSE,sep="\t",quote=FALSE)
	
	#output atr file
	atr=out$hc$merge
	atr.new=atr
	for(i in 1:nrow(atr)){
	 for(j in 1:2){
	   if(atr[i,j]<0){atr.new[i,j]=paste("ARRY",as.character(abs(atr[i,j])),"X",sep="")}
	   if(atr[i,j]>0){atr.new[i,j]=paste("NODE",as.character(abs(atr[i,j])),"X",sep="")}
	}}
        col1=paste("NODE",as.character(1:nrow(atr.new)),"X",sep="")
	atr.new=cbind(col1,atr.new,1-out$hc$height/2)
	output.matrix(atr.new, paste(outputfile.prefix,".atr",sep=""))
	
	if(!is.null(out$hc.features)){
	#output gtr file
	gtr=out$hc.features$merge
	gtr.new=gtr
	for(i in 1:nrow(gtr)){
	 for(j in 1:2){
	   if(gtr[i,j]<0){gtr.new[i,j]=paste("GENE",as.character(abs(gtr[i,j])),"X",sep="")}
	   if(gtr[i,j]>0){gtr.new[i,j]=paste("NODE",as.character(abs(gtr[i,j])),"X",sep="")}
	}}
        col1=paste("NODE",as.character(1:nrow(gtr.new)),"X",sep="")
	gtr.new=cbind(col1,gtr.new,1-out$hc.features$height/2)
	output.matrix(gtr.new, paste(outputfile.prefix,".gtr",sep=""))
}

return()
}


output.matrix <- function(x,file){
  write.table(file=file,x,quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
}



read.gct <- function(file) {
        if (is.character(file))
        if (file == "")
            file <- stdin()
        else {
            file <- file(file, "r")
            on.exit(close(file))
        }
        if (!inherits(file, "connection"))
        stop("argument `file' must be a character string or connection")

   # line 1 version
        version <- readLines(file, n=1)

        # line 2 dimensions
        dimensions <- scan(file, what=list("integer", "integer"), nmax=1, quiet=TRUE)
        rows <- dimensions[[1]]
        columns <- dimensions[[2]]
        # line 3 Name\tDescription\tSample names...
        column.names <- read.table(file, header=FALSE, quote='', nrows=1, sep="\t", fill=FALSE, comment.char='')
        column.names <-column.names[3:length(column.names)]


        if(length(column.names)!=columns) {
                stop(paste("Number of sample names", length(column.names), "not equal to the number of columns", columns, "."))
        }

        colClasses <- c(rep(c("character"), 2), rep(c("double"), columns))

        x <- read.table(file, header=FALSE, quote="", row.names=NULL, comment.char="", sep="\t", colClasses=colClasses, fill=FALSE)
        row.descriptions <- as.character(x[,2])
        data <- as.matrix(x[seq(from=3, to=dim(x)[2], by=1)])

        column.names <- column.names[!is.na(column.names)]

        colnames(data) <- column.names
        row.names(data) <- x[,1]
        return(list(row.descriptions=row.descriptions, data=data))
}


extract.prefix <- function(file){
#  i=0
#  while(substring(file,i,i)!="." & (i <nchar(file))) {i=i+1}
#  if(i==nchar(file)){stop('Error in file name')}
#  pre=substring(file,1,i-1)
#  return(pre)
  tmp <- strsplit(file,"\\.")[[1]]
  return(paste(tmp[-length(tmp)],collapse="."))
}


### Distfun
distfun=function(x){
#if(!is.loaded("distfun")){
#  dyn.load("distfun.so")
#}
n<-nrow(x)
p <- ncol(x)
x[is.na(x)]=0
mode(x)="single"
n2=n*(n-1)/2
junk=.Fortran("distfun",
         x,
        as.integer(n),
       as.integer(p),
       as.integer(n2),
       d=single(n2*p), PACKAGE="sparcl"
)
return(junk$d)
}

```



## Sparse Clustering of NBA Data

We can try assessing the NBA data with sparcl with several different choices for tuning parameters. Initially, we run the model with the default settings and outline some of the relevant outputs: 

+ Weight Vector (p)
+ Dissimilarity metrix U

```{r}
library(sparcl)
nba_mat <- as.matrix(nba[,-c(1:3)]) #needs things taken as a matrix
nba_clust <- nba_mat %>% HierarchicalSparseCluster()

#prints distance matrix
nba_clust$u
# the p-vector of weights
nba_clust$ws
dim(nba_clust$u) #provides the nxn matrix I'm looking for

#tuning parameter
nba_clust$wbound

# plot sparse clustering results
#for data visualizationn
library(Rtsne)
rt1 <- Rtsne(nba_clust$u, perplexity = 10)

#cut at a spot
groups <- cutree(nba_clust$hc, k = 3) #better to cut at number of clusters or dist?
```


## Applying t-SNE to Sparse Clustering Results

We can consider using sparse clustering to regularize the high-dimensional dissimilarity matrices for each dataset. 

```{r}
#for data visualization (not necessarily helpful but nice way to aggregate players)
library(Rtsne); par(mfrow = c(1,1))
set.seed(922019)
rt1 <- Rtsne(nba_clust$u, perp = 10)
plot(rt1$Y, pch = 20, col = factor(groups))
title("T-SNE of Sparse Cluster Results")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)

```

Now I try a couple different tuning parameter values and compare the results. 

```{r}
#wbound is limited by being GREATER than 1
nba_clust2 <- nba_mat %>% HierarchicalSparseCluster(., wbound = 1.1)
nba_clust3 <- nba_mat %>% HierarchicalSparseCluster(., wbound = 2)
nba_clust4 <- nba_mat %>% HierarchicalSparseCluster(., wbound = 10)

```

The below plots compare several different levels of the tuning parameter.  Sparse clustering was used on the data to develop clusters, and then the U matrix that was generated from each version was input into t-SNE. The t-SNE results on the sparse distance matrices was then compared to the solution. 

```{r}
#show the weight vectors
nba_clust2$ws #strong lasso
nba_clust3$ws
nba_clust4$ws #weak penalty

#do the clusters differ? 
groups1 <- cutree(nba_clust2$hc, k = 3)
groups2 <- cutree(nba_clust3$hc, k = 3)
groups3 <- cutree(nba_clust4$hc, k = 3)

#Strong Lasso
rt1 <- Rtsne(nba_clust2$u,perplexity = 10)
plot(rt1$Y, pch = 20, col = factor(groups1))
title("T-SNE of Sparse Cluster Results: Strong Lasso")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)

#Middle Lasso
rt1 <- Rtsne(nba_clust3$u, perplexity = 10)
plot(rt1$Y, pch = 20, col = factor(groups2))
title("T-SNE of Sparse Cluster Results: Medium Lasso")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)


#Weak Lasso
rt1 <- Rtsne(nba_clust4$u, perplexity = 10)
plot(rt1$Y, pch = 20, col = factor(groups3))
title("T-SNE of Sparse Cluster Results: Weak Lasso")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)

```


A function that does this is given below: 

It seems that this runs reasonably well on small datasets but breaks on large ones. 

```{r}
##Prior to using: 
# make sure all non-numeric variables are treated as numeric factors, or remove
# remove all missing observations or impute


sparseTSNE <- function(data, perplexity = 10, lambda = 5, nclust = 3, title = "Sparse t-SNE plot"){
  #data is a data frame, perplexity is used for t-SNE, and lambda is the tuning parameter (>1) for lasso
  #checks to make sure the right packages are loaded
  library(Rtsne)
  library(sparcl)
  #calculates the spares clustering of the data
  temp_mat <- data %>% na.omit() %>% as.matrix() #needs to remove NA and non-numeric data
  clust <- HierarchicalSparseCluster(temp_mat, wbound = lambda)
  
  #use tsne
  tsne1 <- Rtsne(temp_mat, perplexity = perplexity)
  
  #generate the plot
  ##specify grps for colors
  grps <- cutree(clust$hc, k = nclust)
  df <- as.data.frame(tsne1$Y)
  names(df) <- c("X1","X2")
  p <- ggplot(df, aes(X1,X2)) + geom_point(color = factor(grps)) + ggtitle("Sparse TSNE") + theme_bw()
  
return(list(plot = p, cluster_ob = clust))}
```

Testing the function: 
```{r}
#test on a couple datasets
qb_select <- qb %>% dplyr::select(-c(qb,lg,home_away))
sparseTSNE(qb_select) #this produces an error because the dataset is 'large'

#on a smaller size
temp <- dplyr::distinct(qb_select[1:100,])
sparseTSNE(temp)
```


## Optimizing the tuning parameter: 



## Applieed to House Data

Additionally I apply the sparcl methods to real estate transacation data. 

```{r, include = FALSE, eval = FALSE}
house_select <- dplyr::select(house, -c(SalePrice,SaleCondition,SaleType,ID,))
house_mat <- as.matrix(house_mat)
```












