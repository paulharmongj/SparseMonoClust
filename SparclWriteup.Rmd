---
title: "Sparse Clustering Algorithm"
author: "Paul Harmon"
date: "9/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr);library(ggplot2);library(magrittr)
```

## Introduction

## Sparcl packages

Witten includes several of the important functions called by the sparse clustering package in her Github page (link: https://github.com/cran/sparcl). 

## Datasets: 

I'm using a couple of standard datasets that I like to utilize: 

+ NBA pointguards 
+ Colorado housing prices
+ NFL QB stats

```{r}
#reads in datasets
house <- read_csv("data/house_train.csv")
nba <- read_csv("data/na.csv")
qb <- read_csv("data/QBStats_all.csv")
```

Dimensions of the data are shown below: 
```{r}
dim(house)
dim(nba)
dim(qb)
```


## Sparcl Algorithm

The sparse clustering algorithm can be defined for hierarchical clustering as follows: 

+ Initial clustering solution
+ Update the weights w2 (set usually as $\frac{1}{\sqrt{p}}$)
+ Update u, w until convergence
+ Generate the new dissimilarity matrix U (that is now sparse) and perform hierarchical clustering on it

Based on the above methodology, the actual calculation of the sparse clustering is separate from the hierarchical clustering that is performed in the final step. A different clustering method, such as monothetic clustering, could be easily used in the same framework. 

I could easily read in the 'sparcl' package and apply the function; however, instead I'm using Witten's code piece by piece to get a better sense for how the algorithm works and what is necessary to make changes. 

```{r, include = FALSE, eval = FALSE}
#this code reads in Witten's R-code for Sparcl
`HierarchicalSparseCluster` <-
function(x=NULL, dists=NULL, method=c("average", "complete", "single","centroid"), wbound=NULL,niter=15,dissimilarity=c("squared.distance", "absolute.value"), uorth=NULL, silent=FALSE, cluster.features=FALSE, method.features=c("average", "complete", "single","centroid"),output.cluster.files=FALSE, outputfile.prefix="output",genenames=NULL, genedesc=NULL,standardize.arrays=FALSE){
  method <- match.arg(method)
  method.features <- match.arg(method.features)
  dissimilarity <- match.arg(dissimilarity)
  if (is.null(x) && is.null(dists)) stop("x or dists must be given!!!")
  xorig <- x
  if(standardize.arrays){
    if(is.null(x)) stop("Cannot standardize arrays if x not given.")
    dists <- NULL
    x <- sweep(x,1,apply(x,1,mean,na.rm=TRUE),"-")
    x <- sweep(x,1,apply(x,1,sd,na.rm=TRUE),"/")
  }
  if(is.null(dists)){
    xnona <- x
    xnona[is.na(x)] <- 0
    dists <- matrix(distfun(xnona), ncol=ncol(x)) # Rob's Fortran code!!! - no missing values please
    if(sum(is.na(x))>0){
      xbinary <- matrix(1, nrow=nrow(x),ncol=ncol(x))
      xbinary[is.na(x)] <- 0
      mult <- matrix(multfun(xbinary),ncol=ncol(x)) # mult equals 1 if neither elt is NA, and 0 if one or both is NA
      if(dissimilarity=="squared.distance"){
        dists <- sweep(dists,1,sqrt(ncol(dists)/apply(mult!=0,1,sum)),"*")
      } else if (dissimilarity=="absolute.value"){
        dists <- sweep(dists,1,ncol(dists)/apply(mult!=0,1,sum),"*")
      }
      dists[mult==0] <- 0
      mult <- NULL
      xbinary <- NULL
      xnona <- NULL
    }
  }
  if(is.null(wbound)) wbound <- .5*sqrt(ncol(dists))
  if(wbound<=1) stop("Cannot have wbound <= 1")
  if (dissimilarity == "squared.distance") out <- GetUW(dists^2, wbound, niter = niter, uorth = uorth, silent = silent)
  if (dissimilarity == "absolute.value")  out <- GetUW(dists, wbound, niter = niter, uorth = uorth, silent = silent)
  out <- list(hc = hclust(as.dist(out$u), method = method), ws = out$w, u = out$u, crit = out$crit, dists = dists, uorth = uorth, wbound = wbound)

  if(cluster.features){
    if(is.null(x)) stop("Cannot cluster features unless x is given.")
    rho=cor(xorig[,out$ws!=0],use="pairwise.complete.obs")
    out2 <- hclust(as.dist(2*(1-rho)), method=method.features)
    out$hc.features <- out2
  }

  if(output.cluster.files){
    if(is.null(x)) stop("Cannot output files unless x is given.")
    output.cluster.files.fun(xorig,out,outputfile.prefix,genenames=genenames,genedesc=genedesc)
  }
  if(!silent) cat(fill=TRUE)
  class(out) <- "HierarchicalSparseCluster"
  return(out)
}


plot.HierarchicalSparseCluster <- function(x,...){
  par(mfrow=c(1,2))
  plot(x$hc,xlab="",ylab="",sub="", main="Sparse Clustering", labels=rep("", nrow(x$u)))
  plot(x$ws, main=paste("Wbound is ", sep="", round(x$wbound,3)), xlab="Feature Index", ylab="Wj")
}



print.HierarchicalSparseCluster <- function(x,...){
  cat("Wbound is ", x$wbound, ":", fill=TRUE)
  cat("Number of non-zero weights: ", sum(x$ws!=0), fill=TRUE)
  cat("Sum of weights: ", sum(x$ws), fill=TRUE)
  cat(fill=TRUE)
}
```

Additional functions: 
```{r, echo = FALSE, eval = FALSE, include = FALSE}
GetWCSS <- function(x, Cs, ws=NULL){
  wcss.perfeature <- numeric(ncol(x))
  for(k in unique(Cs)){
    whichers <- (Cs==k)
    if(sum(whichers)>1) wcss.perfeature <- wcss.perfeature + apply(scale(x[whichers,],center=TRUE, scale=FALSE)^2, 2, sum)
  }
  bcss.perfeature <- apply(scale(x, center=TRUE, scale=FALSE)^2, 2, sum)-wcss.perfeature
  if(!is.null(ws)) return(list(wcss.perfeature=wcss.perfeature, wcss=sum(wcss.perfeature), wcss.ws=sum(wcss.perfeature*ws),
                               bcss.perfeature=bcss.perfeature))
  if(is.null(ws)) return(list(wcss.perfeature=wcss.perfeature, wcss=sum(wcss.perfeature), bcss.perfeature=bcss.perfeature))
}
 
UpdateCs <- function(x, K, ws, Cs){
  x <- x[,ws!=0]
  z <- sweep(x, 2, sqrt(ws[ws!=0]), "*")
  nrowz <- nrow(z)
  mus <- NULL
  if(!is.null(Cs)){
    for(k in unique(Cs)){
      if(sum(Cs==k)>1) mus <- rbind(mus, apply(z[Cs==k,],2,mean))
      if(sum(Cs==k)==1) mus <- rbind(mus, z[Cs==k,])
    }
  }
  if(is.null(mus)){
    km <- kmeans(z, centers=K, nstart=10)
  } else {
    distmat <- as.matrix(dist(rbind(z, mus)))[1:nrowz, (nrowz+1):(nrowz+K)]
    nearest <- apply(distmat, 1, which.min)
    if(length(unique(nearest))==K){
      km <- kmeans(z, centers=mus)
    } else {
      km <- kmeans(z, centers=K, nstart=10)
    }
  }
  return(km$cluster)
}

#distmat <- function(x){
#  return(dist(x))
#}

BinarySearch <- function(argu,sumabs){
  if(l2n(argu)==0 || sum(abs(argu/l2n(argu)))<=sumabs) return(0)
  lam1 <- 0
  lam2 <- max(abs(argu))-1e-5
  iter <- 1
  while(iter<=15 && (lam2-lam1)>(1e-4)){
    su <- soft(argu,(lam1+lam2)/2)
    if(sum(abs(su/l2n(su)))<sumabs){
      lam2 <- (lam1+lam2)/2
    } else {
      lam1 <- (lam1+lam2)/2
    }
    iter <- iter+1
  }
  return((lam1+lam2)/2)
}

soft <- function(x,d){
  return(sign(x)*pmax(0, abs(x)-d))
}

l2n <- function(vec){
  return(sqrt(sum(vec^2)))
}

GetUW <- function(ds, wbound,niter,uorth,silent){
  # uorth would be a $n^2 x k$ matrix containing $k$ previous
  # dissimilarity matrices found, if we want to do sparse comp clust
  # after having already done $k$ of these things
  # Example:
  # out <- HierarchicalSparseCluster(x,wbound=5)
  # out2 <- HierarchicalSparseCluster(x,wbound=5, uorth=out$u)
  # Then out2 contains a sparse complementary clustering
  p <- ncol(ds)
  w <- rep(1/p, p)*wbound
  iter <- 1
  if(!is.null(uorth)){
    if(sum(abs(uorth-t(uorth)))>1e-10) stop("Uorth must be symmetric!!!!!!!!!!")
    uorth <- matrix(uorth[lower.tri(uorth)],ncol=1)
    uorth <- uorth/sqrt(sum(uorth^2))
  }
  u <- rnorm(nrow(ds))
  w <- rep(1, ncol(ds))
  w.old <- rnorm(ncol(ds))
#  u.old <- rnorm(nrow(ds))
  while(iter<=niter && (sum(abs(w.old-w))/sum(abs(w.old)))>1e-4){#(sum(abs(u.old-u))/sum(abs(u.old)))>1e-4){ # was 1e-3 and involved ws until 11.12.09
    if(!silent) cat(iter,fill=FALSE)
#    u.old <- u
    if(iter>1) u <- ds[,argw>=lam]%*%matrix(w[argw>=lam],ncol=1) 
    if(iter==1) u <- ds%*%matrix(w,ncol=1)
    if(!is.null(uorth)) u <- u - uorth%*%(t(uorth)%*%u)
    iter <- iter+1
    u <- u/l2n(u)
    w.old <- w
    argw <- matrix(pmax(matrix(u,nrow=1)%*%ds,0),ncol=1) 
    lam <- BinarySearch(argw,wbound)
    w <- soft(argw,lam) # Don't need to normalize b/c this will be done soon
    w <- w/l2n(w)
  } 
  u <-  ds[,argw>=lam]%*%matrix(w[argw>=lam],ncol=1)/sum(w)
  if(!is.null(uorth)) u <- u - uorth%*%(t(uorth)%*%u)
  u <- u/l2n(u)
  w <- w/l2n(w)
  crit <- sum(u*(ds%*%matrix(w,ncol=1)))
  u2 <- matrix(0,nrow=ceiling(sqrt(2*length(u))),ncol=ceiling(sqrt(2*length(u))))
  u2[lower.tri(u2)] <- u
  u <- as.matrix(as.dist(u2))/sqrt(2)
  return(list(u=u, w=w, crit=crit))
}

 
UpdateWs <- function(x, Cs, l1bound){
  wcss.perfeature <- GetWCSS(x, Cs)$wcss.perfeature
  tss.perfeature <- GetWCSS(x, rep(1, nrow(x)))$wcss.perfeature
  lam <- BinarySearch(-wcss.perfeature+tss.perfeature, l1bound)
  ws.unscaled <- soft(-wcss.perfeature+tss.perfeature,lam)
  return(ws.unscaled/l2n(ws.unscaled))
}


output.cluster.files.fun <- function(x,out,outputfile.prefix,genenames=NULL,genedesc=NULL){
         p=ncol(x)
         n=nrow(x)
         geneids=dimnames(x)[[2]]
         samplenames=dimnames(x)[[1]]
         if(is.null(geneids)) geneids <- paste("Gene", 1:ncol(x))
         if(is.null(samplenames)) samplenames <- paste("Sample",1:nrow(x))
         if(is.null(genenames)){genenames=geneids}
         if(is.null(genedesc)){genedesc <- rep("", ncol(x))}

         xx=x[,out$ws!=0]
         geneids.subset=geneids[out$ws!=0]
         genenames.subset=genenames[out$ws!=0]
         genedesc.subset=genedesc[out$ws!=0]
         pp=ncol(xx)
         sample.order=out$hc$order
          samplenames.o=samplenames[sample.order]
         arrynames=paste("ARRY",as.character(sample.order),"X",sep="")
         feature.order=1:pp
   if(!is.null(out$hc.features)){feature.order=out$hc.features$order}
    xx.o=xx[sample.order,feature.order]
    geneids.subset.o=geneids.subset[feature.order]
    genenames.subset.o=genenames.subset[feature.order]
    genedesc.subset.o=genedesc.subset[feature.order]
    genex=paste("GENE",as.character(1:pp),"X",sep="")
    genex.o=genex[feature.order]
    arrynames.o=arrynames[sample.order]

# output cdt
	file=paste(outputfile.prefix,".cdt",sep="")
         xprefix <- rbind(c("GID","UID","NAME","GWEIGHT",samplenames.o),c("AID","","","",arrynames))
         xbig <- matrix(NA, ncol=(n+4),nrow=pp)
         for(i in 1:pp){
           xbig[i,] <- c(genex.o[i],geneids.subset.o[i],genedesc.subset.o[i],"1",xx.o[,i]) # was xx
         }
         xbig <- rbind(xprefix,xbig)
         write.table(file=file,xbig,col.names=FALSE,row.names=FALSE,sep="\t",quote=FALSE)
	
	#output atr file
	atr=out$hc$merge
	atr.new=atr
	for(i in 1:nrow(atr)){
	 for(j in 1:2){
	   if(atr[i,j]<0){atr.new[i,j]=paste("ARRY",as.character(abs(atr[i,j])),"X",sep="")}
	   if(atr[i,j]>0){atr.new[i,j]=paste("NODE",as.character(abs(atr[i,j])),"X",sep="")}
	}}
        col1=paste("NODE",as.character(1:nrow(atr.new)),"X",sep="")
	atr.new=cbind(col1,atr.new,1-out$hc$height/2)
	output.matrix(atr.new, paste(outputfile.prefix,".atr",sep=""))
	
	if(!is.null(out$hc.features)){
	#output gtr file
	gtr=out$hc.features$merge
	gtr.new=gtr
	for(i in 1:nrow(gtr)){
	 for(j in 1:2){
	   if(gtr[i,j]<0){gtr.new[i,j]=paste("GENE",as.character(abs(gtr[i,j])),"X",sep="")}
	   if(gtr[i,j]>0){gtr.new[i,j]=paste("NODE",as.character(abs(gtr[i,j])),"X",sep="")}
	}}
        col1=paste("NODE",as.character(1:nrow(gtr.new)),"X",sep="")
	gtr.new=cbind(col1,gtr.new,1-out$hc.features$height/2)
	output.matrix(gtr.new, paste(outputfile.prefix,".gtr",sep=""))
}

return()
}


output.matrix <- function(x,file){
  write.table(file=file,x,quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
}



read.gct <- function(file) {
        if (is.character(file))
        if (file == "")
            file <- stdin()
        else {
            file <- file(file, "r")
            on.exit(close(file))
        }
        if (!inherits(file, "connection"))
        stop("argument `file' must be a character string or connection")

   # line 1 version
        version <- readLines(file, n=1)

        # line 2 dimensions
        dimensions <- scan(file, what=list("integer", "integer"), nmax=1, quiet=TRUE)
        rows <- dimensions[[1]]
        columns <- dimensions[[2]]
        # line 3 Name\tDescription\tSample names...
        column.names <- read.table(file, header=FALSE, quote='', nrows=1, sep="\t", fill=FALSE, comment.char='')
        column.names <-column.names[3:length(column.names)]


        if(length(column.names)!=columns) {
                stop(paste("Number of sample names", length(column.names), "not equal to the number of columns", columns, "."))
        }

        colClasses <- c(rep(c("character"), 2), rep(c("double"), columns))

        x <- read.table(file, header=FALSE, quote="", row.names=NULL, comment.char="", sep="\t", colClasses=colClasses, fill=FALSE)
        row.descriptions <- as.character(x[,2])
        data <- as.matrix(x[seq(from=3, to=dim(x)[2], by=1)])

        column.names <- column.names[!is.na(column.names)]

        colnames(data) <- column.names
        row.names(data) <- x[,1]
        return(list(row.descriptions=row.descriptions, data=data))
}


extract.prefix <- function(file){
#  i=0
#  while(substring(file,i,i)!="." & (i <nchar(file))) {i=i+1}
#  if(i==nchar(file)){stop('Error in file name')}
#  pre=substring(file,1,i-1)
#  return(pre)
  tmp <- strsplit(file,"\\.")[[1]]
  return(paste(tmp[-length(tmp)],collapse="."))
}


### Distfun
distfun=function(x){
#if(!is.loaded("distfun")){
#  dyn.load("distfun.so")
#}
n<-nrow(x)
p <- ncol(x)
x[is.na(x)]=0
mode(x)="single"
n2=n*(n-1)/2
junk=.Fortran("distfun",
         x,
        as.integer(n),
       as.integer(p),
       as.integer(n2),
       d=single(n2*p), PACKAGE="sparcl"
)
return(junk$d)
}

```



## Sparse Clustering of NBA Data

We can try assessing the NBA data with sparcl with several different choices for tuning parameters. Initially, we run the model with the default settings and outline some of the relevant outputs: 

+ Weight Vector (p)
+ Dissimilarity metrix U

```{r}
library(sparcl)
nba_mat <- as.matrix(nba[,-c(1:3)]) #needs things taken as a matrix
nba_clust <- nba_mat %>% HierarchicalSparseCluster()

#prints distance matrix
nba_clust$u
# the p-vector of weights
nba_clust$ws
dim(nba_clust$u) #provides the nxn matrix I'm looking for

#tuning parameter
nba_clust$wbound

# plot sparse clustering results
#for data visualizationn
library(Rtsne)
rt1 <- Rtsne(nba_clust$u, perplexity = 10, is_distance = TRUE)

#cut at a spot
groups <- cutree(nba_clust$hc, k = 3) #better to cut at number of clusters or dist?
```


## Applying t-SNE to Sparse Clustering Results

We can consider using sparse clustering to regularize the high-dimensional dissimilarity matrices for each dataset. The distance matrix U created by the sparse clustering of the data is passed through the 'Rtsne' function in R (as a distance matrix) and the resulting solutions are plotted. 

For the t-SNE, I'm less concerned about the perplexity values than I am the results of the clustering, so I set perplexity equal to 10 for all the NBA examples below. 

```{r}
#for data visualization (not necessarily helpful but nice way to aggregate players)
library(Rtsne); par(mfrow = c(1,1))
set.seed(922019)
rt1 <- Rtsne(nba_clust$u, perp = 10, is_distance = TRUE)
plot(rt1$Y, pch = 20, col = factor(groups))
title("T-SNE of Sparse Cluster Results")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)

```

Now I try a couple different tuning parameter values and compare the results. For the strong lasso penalty I used a wbound of 1.1 (the minimum w value is 1), for moderate I used 2, and for weak I used 10. 

```{r}
#wbound is limited by being GREATER than 1
nba_clust2 <- nba_mat %>% HierarchicalSparseCluster(., wbound = 1.1)
nba_clust3 <- nba_mat %>% HierarchicalSparseCluster(., wbound = 2)
nba_clust4 <- nba_mat %>% HierarchicalSparseCluster(., wbound = 10)

```

The below plots compare several different levels of the tuning parameter.  Sparse clustering was used on the data to develop clusters, and then the U matrix that was generated from each version was input into t-SNE. The t-SNE results on the sparse distance matrices was then compared to the solution. 

The colors are based on a 3-cluster solution. The value of 3 was chosen arbitrarily, but such a choice could be optimized in later work. 

```{r}
#show the weight vectors
nba_clust2$ws #strong lasso
nba_clust3$ws
nba_clust4$ws #weak penalty

#do the clusters differ? 
groups1 <- cutree(nba_clust2$hc, k = 3)
groups2 <- cutree(nba_clust3$hc, k = 3)
groups3 <- cutree(nba_clust4$hc, k = 3)

#Strong Lasso
rt1 <- Rtsne(nba_clust2$u,perplexity = 10, is_distance = TRUE)
plot(rt1$Y, pch = 20, col = factor(groups1))
title("T-SNE of Sparse Cluster Results: Strong Lasso")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)

#Middle Lasso
rt1 <- Rtsne(nba_clust3$u, perplexity = 10, is_distance = TRUE)
plot(rt1$Y, pch = 20, col = factor(groups2))
title("T-SNE of Sparse Cluster Results: Medium Lasso")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)


#Weak Lasso
rt1 <- Rtsne(nba_clust4$u, perplexity = 10, is_distance = TRUE)
plot(rt1$Y, pch = 20, col = factor(groups3))
title("T-SNE of Sparse Cluster Results: Weak Lasso")
text(rt1$Y, pch = 20, label = nba$LAST, cex = 0.5, pos = 3)

```


A function that does this is given below: 

It seems that this runs reasonably well on small datasets but breaks on large ones. This has to do with the functionality of the sparcl call - it cannnot handle datasets in the neighborhood of 10,000 records or larger. 

```{r}
##Prior to using: 
# make sure all non-numeric variables are treated as numeric factors, or remove
# remove all missing observations or impute


sparseTSNE <- function(data, perplexity = 10, lambda = 5, nclust = 3, title = "Sparse t-SNE plot"){
  #data is a data frame, perplexity is used for t-SNE, and lambda is the tuning parameter (>1) for lasso
  #checks to make sure the right packages are loaded
  library(Rtsne)
  library(sparcl)
  #calculates the spares clustering of the data
  temp_mat <- data %>% na.omit() %>% as.matrix() #needs to remove NA and non-numeric data
  clust <- HierarchicalSparseCluster(temp_mat, wbound = lambda)
  
  #use tsne on the DISTANCE MATRIX so make sure is_distance = TRUE 
  tsne1 <- Rtsne(clust$u, perplexity = perplexity, is_distance = TRUE)
  
  #generate the plot
  ##specify grps for colors
  grps <- cutree(clust$hc, k = nclust)
  df <- as.data.frame(tsne1$Y)
  names(df) <- c("X1","X2")
  p <- ggplot(df, aes(X1,X2)) + geom_point(color = factor(grps)) + ggtitle("Sparse TSNE") + theme_bw()
  
return(list(plot = p, cluster_ob = clust))}
```

Testing the function: 
```{r}
#test on a couple datasets
qb_select <- qb %>% dplyr::select(-c(qb,lg,home_away))
#can't run this because it throws an error
#sparseTSNE(qb_select) #this produces an error because the dataset is 'large'

#on a smaller size
temp <- dplyr::distinct(qb_select[1:5000,])
sparseTSNE(temp)
```


## Optimizing the tuning parameter: 

The attached vignette includes some code on how to use the HierarchicalSparseCluster.permute function to pick the 'best' tuning parameter value. Revisiting the NBA data, we can assess the different values of the tuning parameter: 

When interpreting the plot below, the x axis refers to the **number of nonzero weights** not the value of the tuning parameter itself. I add that as text. 

```{r}
 # Do tuning parameter selection for sparse hierarchical clustering
 # Just need to specify a grid for it to search
  perm.out <- HierarchicalSparseCluster.permute(nba_mat, wbounds=c(1.1,seq(1.5,10, by = .5)),
nperms=5)
  print(perm.out)
  plot(perm.out)
  text(perm.out$nnonzerows, perm.out$gaps, labels = perm.out$wbounds, col = "red")
  
```

From the Github page, the code for HierarchicalSparseCluster.permute is included in the code chunk below. The function appears to take default values of 10 permtations and requires a sequence of tuning parameters to consider (with minimum value 1). Dissimilarity is computed as squared Euclidean distance but absolute value can be used as well. 

```{r, eval = FALSE}
HierarchicalSparseCluster.permute <-
function(x,  nperms=10, wbounds=NULL, dissimilarity=c("squared.distance","absolute.value"), standardize.arrays=FALSE){
  dissimilarity <- match.arg(dissimilarity)
  if(is.null(wbounds)) wbounds <- seq(1.1, sqrt(ncol(x))*.7, len=10)
  if(min(wbounds)<=1) stop("Cannot have wbounds <= 1")
  if(length(wbounds)<2) stop("Wbounds should be a vector with at least 2 elements.")
  tots <- rep(NA,length(wbounds))
  permtots <- matrix(NA, nrow=length(wbounds), ncol=nperms)
  nnonzerows <- rep(NA,length(wbounds))
  if(standardize.arrays){
    #x <- t(scale(t(x),T,T))
    x <- sweep(x,1,apply(x,1,mean,na.rm=TRUE),"-")
    x <- sweep(x,1,apply(x,1,sd,na.rm=TRUE),"/")   
  }
  cat("Running sparse hierarchical clustering on unpermuted data",fill=TRUE)
  for(i in 1:length(wbounds)){ 
    cat(i,fill=FALSE)
    if(i==1) out <- HierarchicalSparseCluster(x,  wbound=wbounds[i],silent=TRUE,dissimilarity=dissimilarity)
    if(i>1) out <- HierarchicalSparseCluster(x=NULL,dists=out$dists,wbound=wbounds[i], silent=TRUE,dissimilarity=dissimilarity)
    nnonzerows[i] <- sum(out$ws!=0)
    tots[i] <- out$crit
  }
  cat(fill=TRUE)
  cat("Running sparse hierarchical clustering on permuted data",fill=TRUE)
  permdists <- out$dists
  for(k in 1:nperms){
    cat("Permutation ", k, " of ", nperms,fill=TRUE)
    # Oooohhhh.. It turns out that rather than permuting the columns of x and then computing a dist matrix, we can simply permute
    #  the columns of the (n choose 2)xp dist matrix.
    for(j in 1:ncol(permdists)) permdists[,j] <- sample(permdists[,j])
    for(i in 1:length(wbounds)){
      cat(i,fill=FALSE)
      perm.out <- HierarchicalSparseCluster(x=NULL, dists=permdists,wbound=wbounds[i], silent=TRUE,dissimilarity=dissimilarity)
      permtots[i,k] <- max(perm.out$crit)
    }
    cat(fill=TRUE)
  }
  gaps <- (log(tots)-apply(log(permtots),1,mean))
  out <- list(tots=tots, permtots=permtots, nnonzerows=nnonzerows, gaps=gaps, sdgaps=apply(log(permtots),1,sd), wbounds=wbounds, bestw=wbounds[which.max(gaps)], dists=out$dists)
  class(out) <- "HierarchicalSparseCluster.permute"
  cat(fill=TRUE)
  return(out)
}

print.HierarchicalSparseCluster.permute <- function(x,...){
  cat("Tuning parameter selection results for Sparse Hierarchical Clustering:", fill=TRUE)
  mat <- round(cbind(x$wbounds, x$nnonzerows, x$gaps, x$sdgaps),4)
  dimnames(mat) <- list(1:length(x$wbounds), c("Wbound", "# Non-Zero Ws", "Gap Statistic", "Standard Deviation"))
  print(mat, quote=FALSE)
  cat("Tuning parameter that leads to largest Gap statistic: ", x$bestw, fill=TRUE)
}

plot.HierarchicalSparseCluster.permute <- function(x,...){
  plot(x$nnonzerows, x$gaps, log="x", main="Gap Statistics", xlab="# Non-zero Wjs", ylab="")
  lines(x$nnonzerows, x$gaps)
}
```



##Testing the Function Line-by-Line: 

To better understand what sparcl is doing in the permute method, I tried running each line of code 1 by 1. 

```{r}
#for function args
nperms = 10
wbounds = c(1.1,3,5,7,9)
dissimilarity = "squared.distance"
x <- nba_mat


  
#this code prints errors if something is not specified
  if(is.null(wbounds)) wbounds <- seq(1.1, sqrt(ncol(x))*.7, len=10)
  if(min(wbounds)<=1) stop("Cannot have wbounds <= 1")
  if(length(wbounds)<2) stop("Wbounds should be a vector with at least 2 elements.")
  tots <- rep(NA,length(wbounds))
  permtots <- matrix(NA, nrow=length(wbounds), ncol=nperms) #to be used later, fills up criterion values by each column (for a single permutation). (i.e. this would be wide with 10 wbounds and 100 permutations)
  nnonzerows <- rep(NA,length(wbounds))
  if(standardize.arrays){
    #x <- t(scale(t(x),T,T))
    x <- sweep(x,1,apply(x,1,mean,na.rm=TRUE),"-")
    x <- sweep(x,1,apply(x,1,sd,na.rm=TRUE),"/")   
  }
  #prints the following
  cat("Running sparse hierarchical clustering on unpermuted data",fill=TRUE)
```

The next section takes the wbounds list and calculates the HierarchicalSparseCluster solution at each bound in the sequence. It runs the original iteration on the data and then passes the distance matrix through the resulting iterations. The number of nonzero weights are tracked as are the criterion values  (coming from the getUW function that is called in each iteration in HSC function). 

```{r}
#For each w-value in the wbounds list, the following chunk prints the iteration, then runs the
  #hierarchical sparse cluster (on data in 1st iteration and passes thru to next iters)
  #
  for(i in 1:length(wbounds)){ 
    cat(i,fill=FALSE)
    if(i==1) out <- HierarchicalSparseCluster(x,  wbound=wbounds[i],silent=TRUE,dissimilarity=dissimilarity)
    out_1 <- out
    if(i>1) out <- HierarchicalSparseCluster(x=NULL,dists=out$dists,wbound=wbounds[i], silent=TRUE,dissimilarity=dissimilarity)
    out_k <- out
    nnonzerows[i] <- sum(out$ws!=0)
    tots[i] <- out$crit
  }
#this prints out 5 iterations
  tots
  nnonzerows
```

  
The next phase looks at the permuted data, based on something similar to the gap statistic developed by Tibshirani in 2000. The goal here is to take each column of the nxp dissimilarity matrix and shuffle it. Then, once we have done that, we can cluster based on the 'permuted' distance matrix and return just the maximum criterion value from each iteration at each w bound in each permutation. There will be 10 permutations by default but you can do more if desired. 

```{r}
#quick sanity check
out_k$dists == out1$dists

  cat(fill=TRUE) #prints a space
  cat("Running sparse hierarchical clustering on permuted data",fill=TRUE) #prints this statement
  permdists <- out$dists #the nxp dissimilarity matrix for the last iteration from previous (final iteration) #This is the SAME FOR ALL ITERATIONS SO NO BIGGIE THAT ITS THE LAST ONE
  
for(k in 1:nperms){
    cat("Permutation ", k, " of ", nperms,fill=TRUE) #prints the permutations tracking
    # Oooohhhh.. It turns out that rather than permuting the columns of x and then computing a dist matrix, we can simply permute
    #  the columns of the (n choose 2)xp dist matrix.
  ##Paul: The below code takes each COLUMN of permdists and shuffles the individual elements
    for(j in 1:ncol(permdists)) permdists[,j] <- sample(permdists[,j]) 
    #could have written with an apply
    ##apply(permdists,2,sample) #would do the same thing
    
    
    ### Alternatively, you COULD just permute the columns of the original data matrix X and then create a new distance matrix. I'm going to try this here. 
    nba_permute_dist <- apply(nba[,-c(1:3)], 2, sample) %>% dist()
    
    
    
    #Paul: For the length of W values, calculate the Hierarchical sparse clusters (based on the distance matrix from the previous iterations in the earlier version, and return JUST the 
   for(i in 1:length(wbounds)){
      cat(i,fill=FALSE)
      perm.out <- HierarchicalSparseCluster(x=NULL, dists=permdists,wbound=wbounds[i], silent=TRUE,dissimilarity=dissimilarity)
      permtots[i,k] <- max(perm.out$crit)
    }
    cat(fill=TRUE)
}
  permtots #prints the permuted distance matrix-based criterion values
  
```  
  
Now the gap statsitic can be calculated based on the mean of the permutations. 

```{r} 
length(tots) #5x1 vector
dim(permtots) #5x10 matrix (since 10 permutations were done)

#takes the mean of the permutations to get to a single criterion for each wbound value
  gaps <- (log(tots)-apply(log(permtots),1,mean))
#the formula is defined in the gap statistic paper
#optimal wbound would have the largest gap statistic value
  
# prints the  output for the function
  out <- list(tots=tots, permtots=permtots, nnonzerows=nnonzerows, gaps=gaps, sdgaps=apply(log(permtots),1,sd), wbounds=wbounds, bestw=wbounds[which.max(gaps)], dists=out$dists)
  class(out) <- "HierarchicalSparseCluster.permute"
  cat(fill=TRUE)
  return(out)
#ENDS FUNCTION
```









## Additional Choices we may need to consider

The method used to calculate dissimilarity is something we can change in this code. 


## Applied to House Data

Additionally I apply the sparcl methods to real estate transacation data. 

```{r, include = FALSE, eval = FALSE}
house_select <- dplyr::select(house, -c(SalePrice,SaleCondition,SaleType,ID,))
house_mat <- as.matrix(house_mat)
```












